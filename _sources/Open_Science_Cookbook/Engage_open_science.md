# Engage with Open Science 
*After deepening your understanding of open science, existing policies or practices at your organization may seem as if they need to be updated. **Engage** with open science by asking the following questions. Collaborate with colleagues to consider the next steps that can be taken to adopt open science throughout your research practice or organization.*

Interested in entering into a dialogue with other organizations thinking about these same questions? Join the celebration of the Year of Open Science via the resources in the [Engage with the Year of Open Science Cookbook](/Year_of_Open_Science_Cookbook/Engage_year_of_open_science.md)!

## What can organizations do to change their open science mindset? 
In recent decades, the technological barriers to participating in open science have decreased, but barriers due to policy, bureaucracy, funding, and culture remain. Fully engaging with open science is thus dependent on individuals entering into dialogue with their institutions, universities, agencies and companies to identify changes--both small and large--which will support the move towards open science. 

Building on the work of others over the past several years, TOPS invites individuals, agencies, academic institutions and other organizations to examine the kind of science which they support and encourage, and move towards a more open framework. Join us in our journey, and encourage the pursuit of open scientific progress!  

### We Recommend Everyone Begin Here
We invite all our partners to read and adapt the recommendations from the National Academies of Sciences, Engineering, and Medicine workshop in 2021, “Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop.” Which can be found at [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). 

In particular, the Toolkit Materials in Appendix C provide resources for:
* Drafting an institution statement of support for open science methods and practices (pages 33 to 45)
* Examples of successful and impactful open science work such as the Human Genome Project and the COVID-19 Open Research Dataset (pages 36 to 39)
* A sample template and rubric for assessing a grant/job application for adherence to open science principles (pages 46 to 69)
* A series of short primers on various open-science topics (pages 70 to 92)

### Sources and Recommended Reading

Sources and inspiration for the following suggestions were curated from the work presented in the following publications. Thank you to the contributors, authors, and editors of these reports for sharing the power of open science with the world.

Articles are arranged chronologically and then alphabetically by author/authoring organization. 
* National Academies of Sciences, Engineering, and Medicine 2018. Open Science by Design: Realizing a Vision for 21st Century Research. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25116](https://doi.org/10.17226/25116).
* OA Task Force, Mit and Katharine Dunn. 2018. “Open Access at MIT and Beyond.” MIT Open Access Task Force. [https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf](https://open-access.mit.edu/sites/default/files/20180917_Provost_OpenAccessTF_WhitePaper.pdf) 
* National Academies of Sciences, Engineering, and Medicine 2019. Reproducibility and Replicability in Science. Washington, DC: The National Academies Press. [https://doi.org/10.17226/25303](https://doi.org/10.17226/25303). 
* Open Tech Strategies 2019. Open Source Archetypes: A Framework For Purposeful Open Source. [https://opentechstrategies.com/archetypes](https://opentechstrategies.com/archetypes) 
* Fogel, Karl 2020. Producing Open Source Software How to Run a Successful Free Software Project. [https://producingoss.com/en/social-infrastructure.html](https://producingoss.com/en/social-infrastructure.html#forkability) 
* Hampson, Glenn et al. 2020. “Open Science Roadmap: Recommendations to UNESCO.” [https://doi.org/10.13021/osi2020.2735](https://doi.org/10.13021/osi2020.2735) 
* National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press. [https://doi.org/10.17226/26308](https://doi.org/10.17226/26308). 
* Suominen, Arho. Kauppinen, Henni. Hyytinen, Kirsi. 2021. ‘Gold’, ‘Ribbon’ or ‘Puzzle’: What motivates researchers to work in Research and Technology Organizations. Technological Forecasting & Social Change. [https://doi.org/10.1016/j.techfore.2021.120882](https://doi.org/10.1016/j.techfore.2021.120882) 
* UNESCO. 2021. UNESCO Recommendation on Open Science. [https://en.unesco.org/science-sustainable-future/open-science/recommendation](https://en.unesco.org/science-sustainable-future/open-science/recommendation) 
* Martin S. Hagger (2022) Developing an open science ‘mindset’, Health Psychology and Behavioral Medicine, 10:1, 1-21, DOI: 10.1080/21642850.2021.2012474. [https://doi.org/10.1080/21642850.2021.2012474](https://doi.org/10.1080/21642850.2021.2012474)  
* Miedema, Frank 2022. Open Science: The Very Idea. Utrecht, The Netherlands: Springer Nature. [https://doi.org/10.1007/978-94-024-2115-6](https://doi.org/10.1007/978-94-024-2115-6)

### Recommendations for Government Organizations, Academic Institutions, and NGOs
Recommendations are grouped by theme, with recommended reading or places where more information can be found included where it may be helpful. 

#### Research Products & Data

* Consider the data held in trust by your organization. 
    * Where can researchers find your data? What is your process/method for releasing data? Can portions of it be anonymized such that it can be shared? Is the process for requesting access to your data clear? How fast is the data request process and how often do you go through the process of releasing data? Does your organization have practices around pre-registration and archiving? Are these practices well-known and front-of-mind?
    * [Registry of Research Data Repositories](https://www.re3data.org/) is an example site for finding open databases 
* If your organization produces research, consider if:
    * Research plans may be made available, prior to the start of the project, 
    * That reproducibility/replicability studies be valued and encouraged, and
    * That null/negative results be published. 
    * Some examples of making research plans available can be found at [AsPredicted](https://aspredicted.org/), [Open Science Framework](https://osf.io/), and [Registered Reports](https://cos.io/rr/) 
    * Examples of journals that publish negative/nul results include Positively Negative (PLOS One), The Missing Pieces: A Collection of Negative; Null and Inconclusive Results (PLOS One), The All Results Journals, ACS Omega (ACS Publications), F1000Research, PeerJ, Journal of Negative Results in Biomedicine, Journal of Negative Results: Ecology and Evolutionary Biology, Journal of Articles in Support of the Null Hypothesis, Journal of Pharmaceutical Negative results and Nature Scientific Reports
    * Examples of journals that publish reproducibility/replicability studies are PLOS ONE, and [Royal Society](https://royalsocietypublishing.org/rsos/replication-studies)
* For research produced *for* your organization: 
    * Do you require that the list of materials, study methods, and computational environment be included in the final results which are shared publicly? If not, consider making this a requirement of the project. 
* For data or research produced *by* your organization: 
    * In what languages is the research available? Are bilingual researchers encouraged to apply for funding? Or, better yet, publish in multiple languages? 
    * Consider adding extensions to your databases, publication sites, or other methods of sharing data to allow for easy translation into other languages. 
* Does your organization develop software? 
    * Can this code be made publicly available via GitHub, BitBucket or other mechanisms? 
    * Consider how much of the work of your group ought to be kept “closed” and how much can be made available to advance the work of others, particularly young professionals and early career researchers.
  
#### Metrics & Incentives

* If your organization conducts research, consider the metrics used when evaluating professors, researchers, lab assistants etc. for promotions and opportunities. 
    * What do these metrics *actually* measure? Do these metrics account for historic bias, institutional bias, or other inclusivity or accessibility considerations? Do these metrics account for time and effort spent on research that ultimately produced null and/or negative results? 
    * Explore using alternative metrics that value transparency, reproducibility, replicability, and access. In particular, consider metrics which reflect readability and accessibility of software, code, and data, to encourage and reward researchers who spend time and resources on data science principles 
    * To learn more about this topic, explore work by [Fire and Guestrin](https://academic.oup.com/gigascience/article/8/6/giz053/5506490); [Beall](https://pubs.acs.org/doi/10.1021/acs.jpclett.5b00910); and [Carpenter, Cone and Sarli](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4987709/) in analyzing the impact of traditional metrics for journal publications and research merit 
* Does your institution incentive and reward researchers in which the primary output of the research is code or software development? Consider highlighting work which results in “good code” and valuing publication in “code first” journals equally to those published in other, more traditional journals. 
    * The Journal of Open Source Software and Journal of Open Research Software are two examples of journals which allow for the "traditional" publication of code
  * According to [Suominen *et al*](https://doi.org/10.1016/j.techfore.2021.120882) motivating forces for researchers and scientists are “curiosity, good practice, high-quality science, and making a difference” while de-motivating factors include “collaboration problems, competition, and lack of feedback and recognition for management.” The article goes on to conclude that motivating factors tend to be intrinsic, while the de-motivating factors were often environmental at the organization where the researcher worked. 
    * Consider your organization’s current incentive and recognition structure: is it recognizing motivating factors in those it hires, promotes and praises? 
    * Consider the overall structure for management of research: are any of the de-motivating factors present? Such factors can be minimized by providing researchers with opportunities (both informal and formal) to network, ask for and receive constructive feedback and share their work with those in other fields in addition to their own. 
* It is the suggestion of the [National Academy of Sciences](https://doi.org/10.17226/26308https://doi.org/10.17226/26308) that organizations which are committed to moving towards and advocating for open science should consider the language which is used not only in grants and calls for proposals, but also in prompts for cover letters and resumes, to ensure that the ethos of open science is consistently present. 
    * For example, are applicants for a job asked about their commitment to open science in their recent work? Are post-docs encouraged to make their data open when conducting their work? 
    * An excellent resource on this topic can be found in the [National Academies of Sciences, Engineering, and Medicine. 2021. Developing a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop. Washington, DC: The National Academies Press](https://doi.org/10.17226/26308). 


#### Engaging in Research & Training

* What is the “signaling language” used in grant applications, job postings, and descriptions of research conducted at your organization? 
    * Does this language imply open or closed science practice? Consider updating language where appropriate. 
    * In particular, if your organization has an employee or researcher handbook, review it for language that signals a preference for open or closed science practices. For example, stressing commercialization of ideas encourages people to *not* share their findings in case it could become valuable intellectual property or trade secrets in the future. In contrast, stressing the data sharing can directly enforce an open science ethos. 
* If your organization hires post-docs: are the postdocs also encouraged to engage in open science, or are they measured against different metrics than other researchers? 
* If your organization provides or manages funds for research, consider how the funds are used. Beyond producing results, are funds used for…
    * Research at the intersection of science and society? 
    * Research done by underrepresented/minority researchers? 
    * Research done to directly support underrepresented/minority communities?
    * Research done by early career researchers? 
    * Research done by students (undergraduate and graduate levels)? 
    * Research done to replicate and/or reproduce other studies?
    * Research that produces code? (And do the requirements maintain that this code must be Findable, Accessible, Interoperable, Reusable?)
    * Research that produces data? (And do the requirements maintain that the data must be properly assigned metadata and be made available alongside the results OR prior to the results being published OR in a publicly accessible database so that others may use it?)  
    * Research in which the primary result is code or software development? 
* Does your organization provide training in open science practices such as the use of open databases, or the sharing of open-source software? How about training in bias and anti-bias practices both in the distribution of funding, and in the interpretation of research results (e.g., data dredging, p-hacking and HARK-ing)? 
    * Consider adopting and adapting the [TOPS Open Science curriculum](/docs/Area2_Capacity_Sharing/OpenCore/readme.md), the work of the European Union’s [FOSTER project](https://www.fosteropenscience.eu/toolkit) or/and what has been done by the [Berkeley Initiative for Transparency in the Social Sciences (BITSS)](https://www.bitss.org/resource-library/) to your needs and incentivizing funded researchers to learn more about open science. 
* Does your organization have access to makerspaces? 
    * Who can use them? Are they open to all or only to a certain group? 
    * Consider creating a pathway for community members–particularly high schoolers, study teams organized via libraries, Girl and Boy Scouts, YMCAs, and other organized youth groups–to be able to apply to use these spaces.
* Does your organization have a structured mentoring program for early career researchers? If not, consider creating one. If one already exists, consider incorporating themes of open science into the program.

### Additional Recommendations for Academic Institutions

Some recommendations are most appropriate for academic institutions to tackle, as they relate to academic coursework. We have listed a few of these here, and additionally invite those interested to explore the [Open-Access recommendations by MIT](https://mitl.pubpub.org/pub/future-of-libraries/release/1).

#### Academic Recommendations

* Are both undergraduate and graduate students required to learn about proper statistical analysis and inference? 
    * In particular, do your students understand common problems with statistical analysis which can lead to a lack of accessibility, replicability, and/or reproducibility of the results (e.g., p-hacking, cherry-picking)? 
    * Consider making such knowledge a central tenet of STEM courses at both the undergraduate and graduate levels. 
* For researchers who conduct “field work:” 
    * How do they work with the communities in the field they are studying? If they are being immersed into a community, culture and/or society other than their own, what are your institution's practices and suggestions for that interaction? Are they required to know the language? Study the history and context? Are they required to have partners who are of that community, culture and/or society on their research team? 
    * Consider if your institution may benefit from adjusting the metrics for success in these situations, to include time and incentive for researchers to fully engage with the people most closely affected–either directly or indirectly–by their work. 
    * On a related note, are STEM majors and those pursuing graduate studies in STEM encouraged to study other languages and/or cultures? Are the requirements for a major structured in such a way that they have room in their schedules to pursue those interests? Studying other languages can be a great way to begin to understand the motivations of another community. Next time you review requirements, consider this: what do the requirements of these majors teach students about what is important? 
* We invite academic institutions to read the work of [MIT’s Future of the Libraries Task Force](https://mitl.pubpub.org/pub/future-of-libraries/release/1) from 2016 and consider whether those recommendations, particularly those related to open access, are applicable to your library system.
